# -*- coding: utf-8 -*-
"""
pe_monitoring_llm.py
--------------------
ë‰´ìŠ¤ ìˆ˜ì§‘ â†’ ê·œì¹™ í•„í„°/ë­í‚¹ â†’ OpenAI LLM ì¬í‰ê°€ â†’ í…”ë ˆê·¸ë¨ ì „ì†¡(í•œ ì¤„ ê·¼ê±° í‘œì‹œ ì œì™¸)

ì‚¬ìš© ì „ ì¤€ë¹„
1) ë°°í¬ í™˜ê²½ ë³€ìˆ˜ ë“±ë¡
   - NEWSAPI_KEY, NAVER_CLIENT_ID, NAVER_CLIENT_SECRET (ì„ íƒ), TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID, OPENAI_API_KEY
2) config.json ìŠ¤í‚¤ë§ˆ ì˜ˆì‹œ (í•„ìˆ˜ í‚¤ë§Œ ë‚˜ì—´)
{
  "KEYWORDS": ["PEF", "ì‚¬ëª¨í€ë“œ", "ë°”ì´ì•„ì›ƒ", "ê³µê°œë§¤ìˆ˜", "M&A", "VIG", "MBK", "IMM"],
  "EXCLUDE_KEYWORDS": ["ì—°ì˜ˆ", "ìŠ¤í¬ì¸ ", "ë¸Œëœë“œí‰íŒ"],
  "DOMAIN_WHITELIST": ["www.thebell.co.kr", "dealsite.co.kr", "www.investchosun.com", "n.news.naver.com"],
  "DOMAIN_BLACKLIST": ["entertain.naver.com"],
  "MIN_PUBLISHED_HOURS": 120,
  "PAGE_SIZE": 30,
  "MAX_ITEMS": 60,
  "SHOW_SOURCE_DOMAIN": true,

  "LLM_ENABLE": true,
  "LLM_MODEL": "gpt-4o-mini",
  "LLM_MIN_SCORE": 70,
  "LLM_BATCH_SIZE": 12,
  "LLM_SYSTEM_PROMPT": "ë„ˆëŠ” êµ­ë‚´ ì‚¬ëª¨í€ë“œ/PE ë™í–¥ì„ ì„ ë³„í•˜ëŠ” ë¦¬ì„œì¹˜ ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤...",
  "LLM_USER_TEMPLATE": "ì•„ë˜ ê¸°ì‚¬ë“¤ì„ 0~100ì ìœ¼ë¡œ ì±„ì í•˜ê³ , 60ì  ë¯¸ë§Œì€ dropí•˜ë¼. ê° í•­ëª©ì€ JSONLë¡œ ë‹µí•˜ë¼: {\"keep\":true|false, \"score\":0-100, \"reason\":\"í•œ ì¤„ ê·¼ê±°\"}. ì°¸ê³  í‚¤ì›Œë“œ: {{KEYWORDS}}. ì°¸ê³  ìš´ìš©ì‚¬ watchlist: {{FIRM_WATCHLIST}}.\n\nê¸°ì‚¬ëª©ë¡(JSONL):\n{{ITEMS_JSONL}}",

  "FIRM_WATCHLIST": ["MBK", "IMM", "Hahn&Company", "VIG", "í•œì•¤ì»´í¼ë‹ˆ"]
}
"""

import os
import io
import re
import json
import time
import copy
import logging as log
import datetime as dt
from typing import List, Dict, Any

import requests

CONFIG_PATH = "/mnt/data/config.json"
SENT_CACHE_PATH = "/mnt/data/sent_cache.json"

APP_TZ = dt.timezone(dt.timedelta(hours=9))  # Asia/Seoul

# --------------------------- ìœ í‹¸ ---------------------------

def now_kst() -> dt.datetime:
    return dt.datetime.now(tz=APP_TZ)

def load_json(path: str, default: Any) -> Any:
    try:
        with io.open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return copy.deepcopy(default)

def save_json(path: str, obj: Any) -> None:
    tmp = path + ".tmp"
    with io.open(tmp, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)
    os.replace(tmp, path)

def domain_of(url: str) -> str:
    try:
        return re.sub(r"^www\.", "", requests.utils.urlparse(url).netloc)
    except Exception:
        return ""

def clamp(v: int, lo: int, hi: int) -> int:
    return max(lo, min(hi, v))

def hours_from_utc_now(iso_utc: str) -> float:
    # iso_utc: "2025-10-04T07:30:00Z" ë˜ëŠ” ë¹„ìŠ·í•œ í˜•ì‹
    try:
        if iso_utc.endswith("Z"):
            t = dt.datetime.strptime(iso_utc, "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=dt.timezone.utc)
        else:
            t = dt.datetime.fromisoformat(iso_utc.replace("Z", "+00:00"))
        diff = dt.datetime.now(tz=dt.timezone.utc) - t.astimezone(dt.timezone.utc)
        return diff.total_seconds() / 3600.0
    except Exception:
        return 1e9

# --------------------------- í™˜ê²½/ì„¤ì • ---------------------------

def load_env() -> Dict[str, str]:
    return {
        "NEWSAPI_KEY": os.getenv("NEWSAPI_KEY", ""),
        "NAVER_CLIENT_ID": os.getenv("NAVER_CLIENT_ID", ""),
        "NAVER_CLIENT_SECRET": os.getenv("NAVER_CLIENT_SECRET", ""),
        "TELEGRAM_BOT_TOKEN": os.getenv("TELEGRAM_BOT_TOKEN", ""),
        "TELEGRAM_CHAT_ID": os.getenv("TELEGRAM_CHAT_ID", ""),
        "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY", ""),
    }

def load_cfg() -> Dict[str, Any]:
    default_cfg = {
        "KEYWORDS": [],
        "EXCLUDE_KEYWORDS": [],
        "DOMAIN_WHITELIST": [],
        "DOMAIN_BLACKLIST": [],
        "MIN_PUBLISHED_HOURS": 120,
        "PAGE_SIZE": 30,
        "MAX_ITEMS": 60,
        "SHOW_SOURCE_DOMAIN": True,

        "LLM_ENABLE": False,
        "LLM_MODEL": "gpt-4o-mini",
        "LLM_MIN_SCORE": 70,
        "LLM_BATCH_SIZE": 12,
        "LLM_SYSTEM_PROMPT": "ë„ˆëŠ” êµ­ë‚´ ì‚¬ëª¨í€ë“œ/PE ë™í–¥ì„ ì„ ë³„í•˜ëŠ” ë¦¬ì„œì¹˜ ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤.",
        "LLM_USER_TEMPLATE": "ì•„ë˜ ê¸°ì‚¬ë“¤ì„ 0~100ì ìœ¼ë¡œ ì±„ì í•˜ê³ , 60ì  ë¯¸ë§Œì€ dropí•˜ë¼. ê° í•­ëª©ì€ JSONLë¡œ ë‹µí•˜ë¼: {\"keep\":true|false, \"score\":0-100, \"reason\":\"í•œ ì¤„ ê·¼ê±°\"}.\n\nê¸°ì‚¬ëª©ë¡(JSONL):\n{{ITEMS_JSONL}}",
        "FIRM_WATCHLIST": []
    }
    cfg = load_json(CONFIG_PATH, default_cfg)
    # ì•ˆì „ ë²”ìœ„
    cfg["PAGE_SIZE"] = clamp(int(cfg.get("PAGE_SIZE", 30)), 10, 100)
    cfg["MAX_ITEMS"] = clamp(int(cfg.get("MAX_ITEMS", 60)), 10, 200)
    cfg["LLM_MIN_SCORE"] = clamp(int(cfg.get("LLM_MIN_SCORE", 70)), 0, 100)
    cfg["LLM_BATCH_SIZE"] = clamp(int(cfg.get("LLM_BATCH_SIZE", 12)), 1, 50)
    cfg["MIN_PUBLISHED_HOURS"] = max(0, int(cfg.get("MIN_PUBLISHED_HOURS", 120)))
    return cfg

# --------------------------- ìˆ˜ì§‘ê¸° ---------------------------

def search_newsapi(query: str, page_size: int, api_key: str) -> List[Dict[str, Any]]:
    if not api_key:
        return []
    url = "https://newsapi.org/v2/everything"
    params = {
        "q": query,
        "pageSize": clamp(int(page_size), 10, 100),
        "language": "ko",
        "sortBy": "publishedAt",
    }
    r = requests.get(url, params=params, headers={"X-Api-Key": api_key}, timeout=20)
    r.raise_for_status()
    data = r.json()
    out = []
    for a in data.get("articles", []):
        out.append({
            "title": a.get("title") or "",
            "url": a.get("url") or "",
            "publishedAt": (a.get("publishedAt") or "").replace(".000Z", "Z"),
            "source": (a.get("source") or {}).get("name") or domain_of(a.get("url") or ""),
        })
    return out

def collect_all(cfg: Dict[str, Any], env: Dict[str, str]) -> List[Dict[str, Any]]:
    items: List[Dict[str, Any]] = []
    # ê°„ë‹¨íˆ í‚¤ì›Œë“œ ì¡°í•© 1~2ê°œë§Œ ì‚¬ìš©(ìš´ì˜ í™˜ê²½ì—ì„œ í•„ìš”ì‹œ í™•ì¥)
    q = " OR ".join([f"\"{k}\"" for k in cfg.get("KEYWORDS", [])]) or "ì‚¬ëª¨í€ë“œ OR PEF OR ê³µê°œë§¤ìˆ˜ OR ë°”ì´ì•„ì›ƒ"
    try:
        items.extend(search_newsapi(q, cfg["PAGE_SIZE"], env.get("NEWSAPI_KEY","")))
    except Exception as e:
        log.warning("NewsAPI ìˆ˜ì§‘ ì‹¤íŒ¨: %s", e)

    # ì¤‘ë³µ ì œê±° (url ê¸°ì¤€)
    seen = set()
    uniq = []
    for it in items:
        u = it.get("url","")
        if not u or u in seen:
            continue
        seen.add(u)
        uniq.append(it)
    return uniq[:cfg["MAX_ITEMS"]]

# --------------------------- ê·œì¹™ í•„í„°/ë­í‚¹ ---------------------------

def contains_any(text: str, keywords: List[str]) -> bool:
    text = text or ""
    for k in keywords:
        if k and (k.lower() in text.lower()):
            return True
    return False

def rule_filter(items: List[Dict[str, Any]], cfg: Dict[str, Any]) -> List[Dict[str, Any]]:
    keep = []
    wl = set([re.sub(r"^www\.", "", d) for d in cfg.get("DOMAIN_WHITELIST", [])])
    bl = set([re.sub(r"^www\.", "", d) for d in cfg.get("DOMAIN_BLACKLIST", [])])
    inc = cfg.get("KEYWORDS", [])
    exc = cfg.get("EXCLUDE_KEYWORDS", [])
    min_hours = cfg.get("MIN_PUBLISHED_HOURS", 120)

    for it in items:
        title = it.get("title","")
        url = it.get("url","")
        dom = domain_of(url)
        age_h = hours_from_utc_now(it.get("publishedAt",""))
        if bl and dom in bl:
            continue
        if wl and dom and dom not in wl:
            # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ê°€ ì§€ì •ëœ ê²½ìš° í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì™¸ëŠ” ì»·
            continue
        if exc and contains_any(title, exc):
            continue
        if inc and (not contains_any(title, inc)):
            continue
        if age_h > min_hours:
            continue
        it["_score"] = 0.0
        # ê°„ë‹¨ ê°€ì¤‘ì¹˜: ìµœì‹  + ë„ë©”ì¸ ê°€ì‚°
        it["_score"] += max(0.0, 120.0 - age_h) * 0.2
        if dom in wl:
            it["_score"] += 10.0
        keep.append(it)

    # ê·¼ì‚¬ ì¤‘ë³µ ì œê±°(ì œëª© ìœ ì‚¬ë„ ë‚®ê²Œ)
    out = []
    seen_title = set()
    for it in sorted(keep, key=lambda x: x.get("_score",0.0), reverse=True):
        tnorm = re.sub(r"[\s\W]+", "", it.get("title","").lower())
        if tnorm in seen_title:
            continue
        seen_title.add(tnorm)
        out.append(it)
    return out

def rank_filtered(items: List[Dict[str, Any]], cfg: Dict[str, Any]) -> List[Dict[str, Any]]:
    # ì—¬ê¸°ì„œëŠ” ì´ë¯¸ _scoreê°€ ë¶€ì—¬ë˜ì–´ ìˆìŒ. ìµœì‹ ìˆœ/ìŠ¤ì½”ì–´ìˆœ ì •ë ¬
    items.sort(key=lambda x: (x.get("_score",0.0), x.get("publishedAt","")), reverse=True)
    return items

# --------------------------- LLM ì¬í‰ê°€ ---------------------------

def _jsonl(items: List[Dict[str, Any]]) -> str:
    lines = []
    for it in items:
        lines.append(json.dumps({
            "title": it.get("title",""),
            "url": it.get("url",""),
            "source": domain_of(it.get("url","")),
            "publishedAt": it.get("publishedAt",""),
        }, ensure_ascii=False))
    return "\n".join(lines)

def llm_filter(items: List[Dict[str, Any]], cfg: Dict[str, Any], env: Dict[str, str]) -> List[Dict[str, Any]]:
    if not items:
        return []
    if not cfg.get("LLM_ENABLE", False):
        return items
    api_key = env.get("OPENAI_API_KEY","")
    if not api_key:
        log.info("OPENAI_API_KEY ì—†ìŒ â†’ LLM í•„í„° ìƒëµ")
        return items

    model = cfg.get("LLM_MODEL", "gpt-4o-mini")
    min_score = int(cfg.get("LLM_MIN_SCORE", 70))
    bsz = int(cfg.get("LLM_BATCH_SIZE", 12))
    sys_prompt = cfg.get("LLM_SYSTEM_PROMPT","")
    user_tpl = cfg.get("LLM_USER_TEMPLATE","")
    keywords = ", ".join(cfg.get("KEYWORDS", []))
    firms = ", ".join(cfg.get("FIRM_WATCHLIST", []))

    kept: List[Dict[str, Any]] = []
    for i in range(0, len(items), bsz):
        chunk = items[i:i+bsz]
        user_prompt = user_tpl.replace("{{KEYWORDS}}", keywords).replace("{{FIRM_WATCHLIST}}", firms).replace("{{ITEMS_JSONL}}", _jsonl(chunk))
        try:
            r = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": model,
                    "messages": [
                        {"role":"system","content": sys_prompt},
                        {"role":"user","content": user_prompt}
                    ],
                    "temperature": 0.2
                },
                timeout=40
            )
            r.raise_for_status()
            txt = (r.json()["choices"][0]["message"]["content"] or "").strip()
            # JSONL ê¸°ëŒ€
            sel = []
            for line, it in zip(txt.splitlines(), chunk):
                keep, score = False, 0
                try:
                    obj = json.loads(line)
                    keep = bool(obj.get("keep", False))
                    score = int(obj.get("score", 0))
                    # reason ì €ì¥ì€ í•˜ë˜ ë©”ì‹œì§€ì—ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ(ìš”ì²­ì‚¬í•­)
                    it["_llm_score"] = score
                    it["_llm_reason"] = obj.get("reason", "")
                except Exception:
                    # ë¹„ì •í˜•ì´ë©´ ë³´ìˆ˜ì ìœ¼ë¡œ ë“œë
                    keep, score = False, 0
                if keep and score >= min_score:
                    sel.append(it)
            kept.extend(sel)
        except Exception as e:
            log.warning("LLM í˜¸ì¶œ ì‹¤íŒ¨(%s) â†’ í•´ë‹¹ ë°°ì¹˜ëŠ” ì›ë³¸ ìœ ì§€", e)
            kept.extend(chunk)
        time.sleep(0.2)
    kept.sort(key=lambda x: (x.get("_llm_score",0), x.get("_score",0.0)), reverse=True)
    return kept

# --------------------------- í…”ë ˆê·¸ë¨ ---------------------------

def telegram_send_message(text: str, env: Dict[str, str]) -> bool:
    token = env.get("TELEGRAM_BOT_TOKEN","")
    chat_id = env.get("TELEGRAM_CHAT_ID","")
    if not token or not chat_id:
        log.error("TELEGRAM í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
        return False
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    payload = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": False,
    }
    r = requests.post(url, json=payload, timeout=20)
    try:
        r.raise_for_status()
        return True
    except Exception as e:
        log.error("í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: %s / %s", e, r.text[:200])
        return False

def format_telegram_text(items: List[Dict[str, Any]], cfg: Dict[str, Any]) -> str:
    if not items:
        return "ğŸ“­ ì‹ ê·œ ë‰´ìŠ¤ ì—†ìŒ"
    show_src = bool(cfg.get("SHOW_SOURCE_DOMAIN", True))
    lines = ["ğŸ“Œ <b>êµ­ë‚´ PE ë™í–¥ ê´€ë ¨ ë‰´ìŠ¤</b>"]
    for it in items:
        t = (it.get("title","") or "").strip()
        u = it.get("url","")
        src = domain_of(u)
        when = "-"
        try:
            pub = dt.datetime.strptime(it["publishedAt"], "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=dt.timezone.utc).astimezone(APP_TZ)
            when = pub.strftime("%Y-%m-%d %H:%M")
        except Exception:
            pass
        suffix = f" â€” {src} ({when})" if show_src else f" ({when})"
        lines.append(f"â€¢ <a href=\"{u}\">{t}</a>{suffix}")
    return "\n".join(lines)

# --------------------------- ìºì‹œ ---------------------------

def load_sent_cache() -> Dict[str, Any]:
    d = load_json(SENT_CACHE_PATH, {"sent_urls": []})
    d["sent_urls"] = list(dict.fromkeys(d.get("sent_urls", [])))  # unique
    return d

def update_sent_cache(sent_urls: List[str]) -> None:
    d = load_sent_cache()
    base = set(d.get("sent_urls", []))
    base.update(sent_urls)
    d["sent_urls"] = list(base)[-5000:]  # ìµœê·¼ 5000ê°œë§Œ ìœ ì§€
    save_json(SENT_CACHE_PATH, d)

def filter_already_sent(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    d = load_sent_cache()
    seen = set(d.get("sent_urls", []))
    out = []
    for it in items:
        u = it.get("url","")
        if u and u not in seen:
            out.append(it)
    return out

# --------------------------- íŒŒì´í”„ë¼ì¸ ---------------------------

def transmit_once() -> Dict[str, Any]:
    env = load_env()
    cfg = load_cfg()

    raw = collect_all(cfg, env)
    r1 = rule_filter(raw, cfg)
    ranked = rank_filtered(r1, cfg)
    ranked = llm_filter(ranked, cfg, env)  # LLM ì¬í‰ê°€
    new_items = filter_already_sent(ranked)

    text = format_telegram_text(new_items, cfg)
    ok = telegram_send_message(text, env) if new_items else False

    if ok and new_items:
        update_sent_cache([it.get("url","") for it in new_items])

    return {
        "collected": len(raw),
        "rule_kept": len(r1),
        "ranked": len(ranked),
        "new": len(new_items),
        "sent": ok and bool(new_items)
    }

# --------------------------- ì‹¤í–‰ ---------------------------

if __name__ == "__main__":
    log.basicConfig(level=log.INFO, format="%(asctime)s %(levelname)s %(message)s")
    res = transmit_once()
    print(json.dumps(res, ensure_ascii=False, indent=2))
