import os
import re
import json
import time
import hashlib
import logging
import requests
import datetime as dt
from urllib.parse import urlparse, parse_qs
from typing import Optional, List, Dict, Set

import pytz
import streamlit as st
from apscheduler.schedulers.background import BackgroundScheduler
from threading import Lock

# -------------------------
# ê¸°ë³¸ ì„¤ì • / ì „ì—­ ìƒíƒœ
# -------------------------
APP_TZ = pytz.timezone("Asia/Seoul")
DEFAULT_CONFIG_PATH = os.getenv("PE_CFG", "config.json")
CACHE_FILE = os.getenv("PE_SENT_CACHE", "sent_cache.json")  # ì „ì†¡ ì´ë ¥ ì €ì¥(ì¤‘ë³µ ë°©ì§€)

logging.basicConfig(level=logging.INFO)
log = logging.getLogger("pe_monitor")

# ìŠ¤ì¼€ì¤„ëŸ¬ ì¡ì´ ì°¸ì¡°í•  "í˜„ì¬" êµ¬ì„±/í™˜ê²½ (start_schedule()ì—ì„œ ê°±ì‹ )
CURRENT_CFG_PATH = DEFAULT_CONFIG_PATH
CURRENT_CFG_DICT: Dict = {}     # UIì—ì„œ ì‹œì‘í•  ë•Œ ìŠ¤ëƒ…ìƒ· ì €ì¥ (ì¬ì‹œì‘ ì „ê¹Œì§€ ìœ íš¨)
CURRENT_ENV = {
    "NEWSAPI_KEY": os.getenv("NEWSAPI_KEY", ""),
    "NAVER_CLIENT_ID": os.getenv("NAVER_CLIENT_ID", ""),
    "NAVER_CLIENT_SECRET": os.getenv("NAVER_CLIENT_SECRET", ""),
    "TELEGRAM_BOT_TOKEN": os.getenv("TELEGRAM_BOT_TOKEN", ""),
    "TELEGRAM_CHAT_ID": os.getenv("TELEGRAM_CHAT_ID", ""),
}

# -------------------------
# ê³µìš© ìœ í‹¸
# -------------------------
def load_config(path: str) -> dict:
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        log.warning("config ë¡œë“œ ì‹¤íŒ¨(%s): %s", path, e)
        return {}

def now_kst() -> dt.datetime:
    return dt.datetime.now(APP_TZ)

def clamp(n, lo, hi):
    return max(lo, min(hi, n))

def domain_of(url: str) -> str:
    try:
        return (urlparse(url).netloc or "").replace("www.", "")
    except Exception:
        return ""

def _naver_sid(url: str) -> Optional[str]:
    try:
        q = parse_qs(urlparse(url).query).get("sid", [])
        return q[0] if q else None
    except Exception:
        return None

def sha1(text: str) -> str:
    return hashlib.sha1((text or "").encode("utf-8")).hexdigest()

def is_weekend(kst: dt.datetime) -> bool:
    return kst.weekday() >= 5

def is_holiday(kst: dt.datetime, holidays: List[str]) -> bool:
    ymd = kst.strftime("%Y-%m-%d")
    return ymd in set(holidays or [])

def between_working_hours(kst: dt.datetime, start=8, end=20) -> bool:
    return start <= kst.hour < end

# -------------------------
# ì „ì†¡ ìºì‹œ (ì¤‘ë³µ ë°©ì§€)
# -------------------------
def load_sent_cache() -> Set[str]:
    try:
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            arr = json.load(f)
            return set(arr if isinstance(arr, list) else [])
    except Exception:
        return set()

def save_sent_cache(hashes: Set[str]) -> None:
    try:
        with open(CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(sorted(list(hashes)), f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning("ì „ì†¡ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: %s", e)

# -------------------------
# ì™¸ë¶€ API (Naver / NewsAPI)
# -------------------------
def search_naver_news(keyword: str, client_id: str, client_secret: str, recency_hours=72) -> List[dict]:
    if not client_id or not client_secret or not keyword:
        return []
    base = "https://openapi.naver.com/v1/search/news.json"
    params = {"query": keyword, "display": 30, "sort": "date"}
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret,
    }
    try:
        r = requests.get(base, params=params, headers=headers, timeout=12)
        r.raise_for_status()
        data = r.json()
        items = data.get("items", [])
        res = []
        cutoff = now_kst() - dt.timedelta(hours=recency_hours)
        for it in items:
            link = it.get("link") or it.get("originallink") or ""
            if not link:
                continue
            pubdate = it.get("pubDate")
            try:
                pub_kst = dt.datetime.strptime(pubdate, "%a, %d %b %Y %H:%M:%S %z")
            except Exception:
                pub_kst = now_kst()
            if pub_kst < cutoff:
                continue
            title = re.sub("<.*?>", "", it.get("title") or "")
            res.append({
                "title": title.strip(),
                "url": link.strip(),
                "source": domain_of(link),
                "publishedAt": pub_kst.astimezone(dt.timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
                "origin_keyword": keyword,
                "provider": "naver",
            })
        return res
    except Exception as e:
        log.warning("Naver ì˜¤ë¥˜(%s): %s", keyword, e)
        return []

def search_newsapi(query: str, page_size: int, api_key: str, from_hours: int = 72, cfg: dict = None) -> List[dict]:
    if not api_key or not query:
        return []
    base = "https://newsapi.org/v2/everything"
    from_dt = (dt.datetime.now(dt.timezone.utc) - dt.timedelta(hours=from_hours))
    params = {
        "q": (cfg.get("NEWSAPI_QUERY") if (cfg and cfg.get("NEWSAPI_QUERY")) else query),
        "searchIn": "title",
        "pageSize": clamp(page_size, 10, 100),
        "language": "ko",
        "sortBy": "publishedAt",
        "from": from_dt.strftime("%Y-%m-%dT%H:%M:%SZ"),
        "apiKey": api_key,
    }
    if cfg and cfg.get("NEWSAPI_DOMAINS"):
        params["domains"] = ",".join(cfg["NEWSAPI_DOMAINS"])
    try:
        r = requests.get(base, params=params, timeout=12)
        r.raise_for_status()
        data = r.json()
        arts = data.get("articles", [])
        res = []
        for a in arts:
            title = (a.get("title") or "").strip()
            url = (a.get("url") or "").strip()
            if not title or not url:
                continue
            res.append({
                "title": title,
                "url": url,
                "source": domain_of(url) or (a.get("source", {}) or {}).get("name", ""),
                "publishedAt": (a.get("publishedAt") or "").replace(".000Z", "Z"),
                "origin_keyword": "_newsapi",
                "provider": "newsapi",
            })
        return res
    except Exception as e:
        log.warning("NewsAPI ì˜¤ë¥˜: %s", e)
        return []

# -------------------------
# ì¤‘ë³µ ì œê±° ê°•í™” (URL/ì œëª© ì •ê·œí™” + ê·¼ì‚¬ ì¤‘ë³µ)
# -------------------------
NAVER_ART_RE = re.compile(r"/article/(\d{3})/(\d{10})")
NOISE_TAGS = {"ë‹¨ë…","ì†ë³´","ì‹œê·¸ë„","fnë§ˆì¼“ì›Œì¹˜","íˆ¬ì360","ì˜ìƒ","í¬í† ","ë¥´í¬","ì‚¬ì„¤","ì¹¼ëŸ¼","ë¶„ì„"}
BRACKET_RE   = re.compile(r"[\[\(ï¼ˆ](.*?)[\]\)ï¼‰]")
MULTISPACE_RE = re.compile(r"\s+")
SYNONYM_MAP = {
    "immì¸ë² ìŠ¤íŠ¸ë¨¼íŠ¸": "immì¸ë² ",
    "imm ì¸ë² ìŠ¤íŠ¸ë¨¼íŠ¸": "immì¸ë² ",
    "imm investment": "immì¸ë² ",
    "mergers & acquisitions": "m&a",
    "ì¸ë² ìŠ¤íŠ¸ë¨¼íŠ¸": "ì¸ë² ",
}

def canonical_url_id(url: str) -> str:
    """ê°™ì€ ê¸°ì‚¬ë¥¼ ë™ì¼ í‚¤ë¡œ ë¬¶ê¸° ìœ„í•œ ì •ê·œí™” ID ìƒì„±."""
    try:
        u = urlparse(url)
        host = (u.netloc or "").replace("www.", "")
        path = u.path or ""
        if host.endswith("naver.com"):
            m = NAVER_ART_RE.search(path)
            if m:
                oid, aid = m.group(1), m.group(2)
                return f"naver:{oid}:{aid}"
        base = f"{host}{path}".rstrip("/")
        return re.sub(r"/+$", "", base)
    except Exception:
        return url

def normalize_title(t: str) -> str:
    if not t:
        return ""
    s = t
    # ê´„í˜¸/ëŒ€ê´„í˜¸ ì•ˆì˜ íƒœê·¸ì„± í† í° ì œê±°
    def _strip_noise(m):
        inner = (m.group(1) or "").strip()
        return "" if any(tag in inner.replace(" ", "") for tag in NOISE_TAGS) else inner
    s = BRACKET_RE.sub(_strip_noise, s)
    # ë¨¸ë¦¬ë§ íƒœê·¸ ì œê±°
    for tag in NOISE_TAGS:
        s = re.sub(rf"^\s*(?:\[{tag}\]|\({tag}\))\s*", "", s, flags=re.IGNORECASE)
    # íŠ¹ìˆ˜ë¬¸ì/ë§ì¤„ì„í‘œ ì •ë¦¬
    s = s.replace("â€¦", " ").replace("ã†", " ").replace("Â·", " ").replace("â€”", " ")
    # ë™ì˜ì–´ í†µì¼ (ì†Œë¬¸ì)
    s_low = s.lower()
    for k, v in SYNONYM_MAP.items():
        s_low = s_low.replace(k, v)
    # ìˆ«ì ì½¤ë§ˆ ì •ê·œí™”
    s_low = re.sub(r"\b(\d{1,3}(,\d{3})+|\d+)\b", lambda m: m.group(0).replace(",", ""), s_low)
    # ê³µë°± ì •ë¦¬
    s_low = MULTISPACE_RE.sub(" ", s_low).strip()
    return s_low

def _tokens(s: str) -> set:
    return {w for w in re.split(r"[^0-9a-zA-Zê°€-í£]+", s) if len(w) >= 2}

def _bigrams(s: str) -> set:
    return {s[i:i+2] for i in range(len(s)-1)} if len(s) > 1 else set()

def is_near_dup(a: str, b: str) -> bool:
    """ì •ê·œí™” ì œëª© a,b ê·¼ì ‘ ì¤‘ë³µ íŒë‹¨."""
    if not a or not b:
        return False
    if a == b:
        return True
    ta, tb = _tokens(a), _tokens(b)
    if ta and tb:
        j_tok = len(ta & tb) / max(1, len(ta | tb))
        if j_tok >= 0.70:
            return True
    ba, bb = _bigrams(a), _bigrams(b)
    if ba and bb:
        j_bg = len(ba & bb) / max(1, len(ba | bb))
        if j_bg >= 0.55:
            return True
    if a in b or b in a:
        return True
    return False

def dedup(items: List[dict]) -> List[dict]:
    """URL ì •ê·œí™” â†’ ì œëª© ê·¼ì‚¬ ì¤‘ë³µ ì œê±° 2ë‹¨ê³„."""
    out, seen_by_id, seen_titles = [], set(), []
    for it in items:
        url = it.get("url", "")
        cid = canonical_url_id(url)
        if cid in seen_by_id:
            continue
        norm_t = normalize_title(it.get("title", ""))
        dup = False
        for prev_norm, _idx in seen_titles:
            if is_near_dup(norm_t, prev_norm):
                dup = True
                break
        if dup:
            continue
        seen_by_id.add(cid)
        seen_titles.append((norm_t, len(out)))
        out.append(it)
    return out

# -------------------------
# í•„í„°/ì •ë ¬
# -------------------------
def should_drop(item: dict, cfg: dict) -> bool:
    url = item.get("url", "")
    title = (item.get("title") or "").strip()
    if not url or not title:
        return True

    src = domain_of(url)
    allow = set(cfg.get("ALLOW_DOMAINS", []) or [])
    block = set(cfg.get("BLOCK_DOMAINS", []) or [])
    allow_strict = bool(cfg.get("ALLOWLIST_STRICT", False))

    if src in block:
        return True
    if allow_strict and allow and (src not in allow):
        return True

    # ë„¤ì´ë²„ ì„¹ì…˜ ì œí•œ(ì˜ˆ: ê²½ì œë©´=101)
    if "naver.com" in src:
        sids = set(cfg.get("NAVER_ALLOW_SIDS", []) or [])
        if sids:
            sid = _naver_sid(url)
            if sid not in sids:
                return True

    # ì œëª© í¬í•¨/ì œì™¸ í‚¤ì›Œë“œ
    include = (cfg.get("INCLUDE_TITLE_KEYWORDS", []) or [])
    if include and not any(w.lower() in title.lower() for w in include):
        return True
    for w in (cfg.get("EXCLUDE_TITLE_KEYWORDS", []) or []):
        if w and w.lower() in title.lower():
            return True

    return False

def score_item(item: dict, cfg: dict) -> float:
    # ê°„ë‹¨ ê°€ì¤‘ì¹˜: ë„ë©”ì¸ ê°€ì¤‘ì¹˜ + ì‹ ì„ ë„
    src = domain_of(item.get("url", ""))
    score = float((cfg.get("DOMAIN_WEIGHTS", {}) or {}).get(src, 1.0))
    try:
        ts = item.get("publishedAt")
        pub = dt.datetime.strptime(ts, "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=dt.timezone.utc)
    except Exception:
        pub = now_kst()
    hours_ago = (now_kst() - pub.astimezone(APP_TZ)).total_seconds() / 3600.0
    score += max(0.0, 6.0 - (hours_ago / 8.0))
    return score

def rank_filtered(items: List[dict], cfg: dict) -> List[dict]:
    arr = [it for it in items if not should_drop(it, cfg)]
    for it in arr:
        it["_score"] = score_item(it, cfg)
    arr.sort(key=lambda x: x["_score"], reverse=True)
    return dedup(arr)

# -------------------------
# ìˆ˜ì§‘/ì „ì†¡
# -------------------------
def collect_all(cfg: dict, env: dict) -> List[dict]:
    keywords = cfg.get("KEYWORDS", []) or []
    page_size = int(cfg.get("PAGE_SIZE", 30))
    recency_hours = int(cfg.get("RECENCY_HOURS", 72))

    all_items: List[dict] = []

    # Naver
    for kw in keywords:
        batch = search_naver_news(kw, env.get("NAVER_CLIENT_ID", ""), env.get("NAVER_CLIENT_SECRET", ""), recency_hours=recency_hours)
        all_items += batch
        time.sleep(0.2)

    # NewsAPI (ì„ íƒ)
    if env.get("NEWSAPI_KEY") and keywords:
        query = " OR ".join(keywords)
        batch = search_newsapi(query, page_size=page_size, api_key=env["NEWSAPI_KEY"], from_hours=recency_hours, cfg=cfg)
        all_items += batch

    return all_items

def format_telegram_text(items: List[dict]) -> str:
    if not items:
        return "ğŸ“­ ì‹ ê·œ ë‰´ìŠ¤ ì—†ìŒ"
    lines = ["ğŸ“Œ <b>êµ­ë‚´ PE ë™í–¥ ê´€ë ¨ ë‰´ìŠ¤</b>"]
    for it in items:
        t = it.get("title", "").strip()
        u = it.get("url", "")
        try:
            pub = dt.datetime.strptime(it["publishedAt"], "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=dt.timezone.utc).astimezone(APP_TZ)
            when = pub.strftime("%Y-%m-%d %H:%M")
        except Exception:
            when = "-"
        # ì œëª©=ë§í¬, ì¶œì²˜ ë„ë©”ì¸ ë¯¸í‘œì‹œ
        lines.append(f"â€¢ <a href=\"{u}\">{t}</a> ({when})")
    return "\n".join(lines)

def send_telegram(bot_token: str, chat_id: str, text: str) -> bool:
    if not bot_token or not chat_id:
        return False
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    payload = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True,
    }
    try:
        r = requests.post(url, json=payload, timeout=12)
        r.raise_for_status()
        return True
    except Exception as e:
        log.warning("í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: %s", e)
        return False

def _should_skip_by_time(cfg: dict) -> bool:
    """ì—…ë¬´ì‹œê°„/ì£¼ë§/ê³µíœ´ì¼ ì˜µì…˜ì— ë”°ë¼ ì „ì†¡ì„ ê±´ë„ˆë›¸ì§€ íŒë‹¨"""
    kst_now = now_kst()
    if cfg.get("ONLY_WORKING_HOURS") and not between_working_hours(kst_now, 8, 20):
        return True
    if cfg.get("BLOCK_WEEKEND") and is_weekend(kst_now):
        return True
    if cfg.get("BLOCK_HOLIDAY") and is_holiday(kst_now, cfg.get("HOLIDAYS", [])):
        return True
    return False

# -------------------------
# ì‹¤í–‰ ê²¹ì¹¨ ë°©ì§€ ë½
# -------------------------
@st.cache_resource(show_spinner=False)
def get_run_lock() -> Lock:
    return Lock()

def transmit_once(cfg: dict, env: dict, preview=False) -> dict:
    # ì‹¤í–‰ ê²¹ì¹¨ ë°©ì§€ (ë™ì‹œì— ë‘ ë²ˆ ì´ìƒ ëŒì§€ ì•Šë„ë¡)
    run_lock = get_run_lock()
    if not run_lock.acquire(blocking=False):
        log.info("ë‹¤ë¥¸ ì‹¤í–‰ì´ ì§„í–‰ ì¤‘ì´ì–´ì„œ ì´ë²ˆ ì£¼ê¸°ëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤.")
        return {"count": 0, "items": []}
    try:
        # ì „ì²´ ìˆ˜ì§‘ â†’ í•„í„°/ì •ë ¬ â†’ ì „ì²´ ë¦¬ìŠ¤íŠ¸
        all_items = collect_all(cfg, env)
        ranked = rank_filtered(all_items, cfg)

        if preview:
            return {"count": len(ranked), "items": ranked}

        # ì „ì†¡ íƒ€ì„ í•„í„°
        if _should_skip_by_time(cfg):
            log.info("ì‹œê°„ ì •ì±…ì— ì˜í•´ ì „ì†¡ ê±´ë„ˆëœ€ (ì—…ë¬´ì‹œê°„/ì£¼ë§/ê³µíœ´ì¼)")
            return {"count": 0, "items": []}

        # ì‹ ê·œë§Œ ì „ì†¡ (ìºì‹œ ê¸°ì¤€)
        cache = load_sent_cache()
        new_items = [it for it in ranked if sha1(it.get("url", "")) not in cache]

        # ì‹ ê·œ ì—†ìœ¼ë©´ ì•Œë¦¼
        if not new_items:
            send_telegram(env.get("TELEGRAM_BOT_TOKEN", ""), env.get("TELEGRAM_CHAT_ID", ""), "ğŸ“­ ì‹ ê·œ ë‰´ìŠ¤ ì—†ìŒ")
            return {"count": 0, "items": []}

        # í…”ë ˆê·¸ë¨ 4096ì ì œí•œ ëŒ€ë¹„ â€” 30ê°œ ë‹¨ìœ„ë¡œ ë°°ì¹˜ ì „ì†¡
        BATCH = 30
        sent_any = False
        for i in range(0, len(new_items), BATCH):
            chunk = new_items[i:i+BATCH]
            text = format_telegram_text(chunk)
            ok = send_telegram(env.get("TELEGRAM_BOT_TOKEN", ""), env.get("TELEGRAM_CHAT_ID", ""), text)
            sent_any = sent_any or ok
            time.sleep(0.6)

        if sent_any:
            cache |= {sha1(it.get("url", "")) for it in new_items}
            save_sent_cache(cache)

        return {"count": len(new_items), "items": new_items}
    finally:
        run_lock.release()

# -------------------------
# ìŠ¤ì¼€ì¤„ëŸ¬ (rerun-safe)
# -------------------------
@st.cache_resource(show_spinner=False)
def get_scheduler() -> BackgroundScheduler:
    sched = BackgroundScheduler(timezone=APP_TZ)
    sched.start()
    return sched

def scheduled_job():
    # UIì—ì„œ ìŠ¤ëƒ…ìƒ·ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ìš°ì„  ì‚¬ìš©
    cfg = CURRENT_CFG_DICT or load_config(CURRENT_CFG_PATH)
    try:
        transmit_once(cfg, CURRENT_ENV, preview=False)
    except Exception as e:
        log.exception("ìŠ¤ì¼€ì¤„ ì‘ì—… ì‹¤íŒ¨: %s", e)

def ensure_interval_job(sched: BackgroundScheduler, minutes: int):
    job_id = "pe_news_job"
    try:
        sched.remove_job(job_id)
    except Exception:
        pass
    # next_run_time=now â†’ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì¦‰ì‹œ 1íšŒ ì‹¤í–‰ì„ íŠ¸ë¦¬ê±° (ìˆ˜ë™ í˜¸ì¶œ ê¸ˆì§€)
    sched.add_job(scheduled_job, "interval", minutes=minutes, id=job_id,
                  replace_existing=True, next_run_time=now_kst())

def is_running(sched: BackgroundScheduler) -> bool:
    try:
        return any(j.id == "pe_news_job" for j in sched.get_jobs())
    except Exception:
        return False

# ìŠ¤ì¼€ì¤„ ì‹œì‘/ì¤‘ì§€(ë²„íŠ¼ í•¸ë“¤ëŸ¬ìš©) â€” ì—¬ê¸°ì„œë§Œ global ì‚¬ìš©
def start_schedule(cfg_path: str, cfg_dict: dict, env: dict, minutes: int):
    global CURRENT_CFG_PATH, CURRENT_CFG_DICT, CURRENT_ENV
    CURRENT_CFG_PATH = cfg_path
    CURRENT_CFG_DICT = dict(cfg_dict)  # UI ì¡°ì • ì˜µì…˜ê¹Œì§€ ìŠ¤ëƒ…ìƒ· ì €ì¥
    CURRENT_ENV = env
    sched = get_scheduler()
    ensure_interval_job(sched, minutes)
    # ì£¼ì˜: ì¦‰ì‹œ ì‹¤í–‰ì€ ìŠ¤ì¼€ì¤„ëŸ¬ next_run_timeìœ¼ë¡œë§Œ ìœ ë„(ìˆ˜ë™ scheduled_job() í˜¸ì¶œ ê¸ˆì§€)

def stop_schedule():
    sched = get_scheduler()
    try:
        sched.remove_job("pe_news_job")
    except Exception:
        pass

# -------------------------
# Streamlit UI
# -------------------------
st.set_page_config(page_title="PE ë™í–¥ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§", page_icon="ğŸ“°", layout="wide")

# Config / ìê²©ì¦ëª…
cfg_path = st.sidebar.text_input("config.json ê²½ë¡œ", value=DEFAULT_CONFIG_PATH)
cfg_file = load_config(cfg_path)
st.sidebar.caption(f"Config ë¡œë“œ ìƒíƒœ: {'âœ…' if cfg_file else 'âŒ'}  Â· ê²½ë¡œ: {cfg_path}")

# íŒŒì¼ì˜ ê¸°ë³¸ê°’ì„ UI ëŸ°íƒ€ì„ cfgë¡œ ë³µì‚¬
cfg = dict(cfg_file)

naver_id = st.sidebar.text_input("Naver Client ID", type="password", value=os.getenv("NAVER_CLIENT_ID", ""))
naver_secret = st.sidebar.text_input("Naver Client Secret", type="password", value=os.getenv("NAVER_CLIENT_SECRET", ""))
newsapi_key = st.sidebar.text_input("NewsAPI Key (ì„ íƒ)", type="password", value=os.getenv("NEWSAPI_KEY", ""))
bot_token = st.sidebar.text_input("Telegram Bot Token", type="password", value=os.getenv("TELEGRAM_BOT_TOKEN", ""))
chat_id = st.sidebar.text_input("Telegram Chat ID (ì±„ë„/ê·¸ë£¹)", value=os.getenv("TELEGRAM_CHAT_ID", ""))

# íŒŒë¼ë¯¸í„°
st.sidebar.divider()
st.sidebar.subheader("ì „ì†¡/ìˆ˜ì§‘ íŒŒë¼ë¯¸í„°")
cfg["PAGE_SIZE"] = int(st.sidebar.number_input("í˜ì´ì§€ë‹¹ ìˆ˜ì§‘ ìˆ˜", min_value=10, max_value=100, step=1, value=int(cfg.get("PAGE_SIZE", 30))))
cfg["INTERVAL_MIN"] = int(st.sidebar.number_input("ì „ì†¡ ì£¼ê¸°(ë¶„)", min_value=5, max_value=360, step=5, value=int(cfg.get("INTERVAL_MIN", cfg.get("TRANSMIT_INTERVAL_MIN", 60)))))
cfg["RECENCY_HOURS"] = int(st.sidebar.number_input("ì‹ ì„ ë„(ìµœê·¼ Nì‹œê°„)", min_value=6, max_value=168, step=6, value=int(cfg.get("RECENCY_HOURS", 72))))

# âœ… ì‹œê°„ ì •ì±… í† ê¸€
st.sidebar.subheader("ì‹œê°„ ì •ì±…")
cfg["ONLY_WORKING_HOURS"] = bool(st.sidebar.checkbox("âœ… ì—…ë¬´ì‹œê°„(08~20 KST) ë‚´ ì „ì†¡", value=bool(cfg.get("ONLY_WORKING_HOURS", True))))
cfg["BLOCK_WEEKEND"]     = bool(st.sidebar.checkbox("ğŸš« ì£¼ë§ ë¯¸ì „ì†¡", value=bool(cfg.get("BLOCK_WEEKEND", True))))
cfg["BLOCK_HOLIDAY"]     = bool(st.sidebar.checkbox("ğŸš« ê³µíœ´ì¼ ë¯¸ì „ì†¡", value=bool(cfg.get("BLOCK_HOLIDAY", False))))
holidays_text = st.sidebar.text_area("ê³µíœ´ì¼(YYYY-MM-DD, ì‰¼í‘œ ë˜ëŠ” ì¤„ë°”ê¿ˆ êµ¬ë¶„)", value=", ".join(cfg.get("HOLIDAYS", [])))
cfg["HOLIDAYS"] = [s.strip() for s in re.split(r"[,\n]", holidays_text) if s.strip()]

# ê¸°íƒ€ í•„í„° í† ê¸€
st.sidebar.subheader("ê¸°íƒ€ í•„í„°")
cfg["ALLOWLIST_STRICT"] = bool(st.sidebar.checkbox("ğŸ§± ALLOWLIST_STRICT (í—ˆìš© ë„ë©”ì¸ ì™¸ ì°¨ë‹¨)", value=bool(cfg.get("ALLOWLIST_STRICT", True))))

st.sidebar.divider()
if st.sidebar.button("êµ¬ì„± ë¦¬ë¡œë“œ", use_container_width=True):
    st.experimental_rerun()

st.title("ğŸ“° êµ­ë‚´ PE ë™í–¥ ë‰´ìŠ¤ ìë™ ëª¨ë‹ˆí„°ë§")
st.caption("Streamlit + Naver/NewsAPI + Telegram + APScheduler (Render + UptimeRobot)")

def make_env() -> dict:
    return {
        "NAVER_CLIENT_ID": naver_id,
        "NAVER_CLIENT_SECRET": naver_secret,
        "NEWSAPI_KEY": newsapi_key,
        "TELEGRAM_BOT_TOKEN": bot_token,
        "TELEGRAM_CHAT_ID": chat_id,
    }

col1, col2, col3, col4 = st.columns(4)
sched = get_scheduler()

with col1:
    if st.button("ì§€ê¸ˆ í•œë²ˆ ì‹¤í–‰(ë¯¸ë¦¬ë³´ê¸°)", type="primary"):
        res = transmit_once(cfg, make_env(), preview=True)
        st.session_state["preview"] = res

with col2:
    if st.button("ì§€ê¸ˆ í•œë²ˆ ì „ì†¡"):
        res = transmit_once(cfg, make_env(), preview=False)
        st.session_state["preview"] = res

with col3:
    if st.button("ìŠ¤ì¼€ì¤„ ì‹œì‘"):
        start_schedule(cfg_path=cfg_path, cfg_dict=cfg, env=make_env(), minutes=int(cfg["INTERVAL_MIN"]))
        st.success("ìŠ¤ì¼€ì¤„ ì‹œì‘ë¨ (ì¦‰ì‹œ 1íšŒ ì „ì†¡ í›„ ì£¼ê¸° ì‹¤í–‰)")

with col4:
    if st.button("ìŠ¤ì¼€ì¤„ ì¤‘ì§€"):
        stop_schedule()
        st.warning("ìŠ¤ì¼€ì¤„ ì¤‘ì§€ë¨")

# ìƒíƒœ
_running = is_running(sched)
st.subheader("ìƒíƒœ")
st.info(f"Scheduler ì‹¤í–‰ ì¤‘: {_running}")

# ë¯¸ë¦¬ë³´ê¸° ê²°ê³¼ â€” ì „ì²´ í•„í„°ë§ ê¸°ì‚¬ë§Œ í‘œì‹œ (Top10 ì—†ìŒ)
st.subheader("ğŸ“‹ í•„í„°ë§ëœ ì „ì²´ ê¸°ì‚¬")
res = st.session_state.get("preview", {"items": []})
items = res.get("items", [])
if not items:
    st.write("ê²°ê³¼ ì—†ìŒ")
else:
    for it in items:
        t = it.get("title", "")
        u = it.get("url", "")
        try:
            pub = dt.datetime.strptime(it["publishedAt"], "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=dt.timezone.utc).astimezone(APP_TZ)
            when = pub.strftime("%Y-%m-%d %H:%M")
        except Exception:
            when = "-"
        st.markdown(f"- <a href='{u}'>{t}</a> ({when})", unsafe_allow_html=True)
